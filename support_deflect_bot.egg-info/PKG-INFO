Metadata-Version: 2.1
Name: support-deflect-bot
Version: 0.1.0
Summary: Intelligent document Q&A with confidence-based refusal
Home-page: https://github.com/yourusername/support-deflect-bot
Author: Your Name
Author-email: your.email@example.com
License: UNKNOWN
Platform: UNKNOWN
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Python: >=3.9
Description-Content-Type: text/markdown
License-File: LICENSE

# Support Deflection Bot

**ü§ñ Intelligent document Q&A with confidence-based refusal**

Transform your documentation into a smart assistant that answers questions accurately or refuses gracefully. Built for reliability over chattiness.

## Quick Start (5 minutes)

```bash
# 1. Install Ollama and models
curl -fsSL https://ollama.com/install.sh | sh
ollama pull llama3.1
ollama pull nomic-embed-text

# 2. Clone and setup
git clone <repo-url>
cd support-deflect-bot
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt

# 3. Start the API
uvicorn src.api.app:app --reload

# 4. Index your docs and ask questions
curl -X POST http://127.0.0.1:8000/reindex
curl -X POST http://127.0.0.1:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "How do I configure the system?"}'
```

## What makes this different?

‚ùå **Most AI assistants**: Answer confidently but make things up  
‚úÖ **This bot**: Refuses to answer when unsure, provides citations, measures confidence

### Core Behaviors
- **Grounded answers**: Only uses your provided documentation
- **Confident refusal**: Says "I don't have enough information" when evidence is weak
- **Citation tracking**: Shows exactly where answers come from
- **Confidence scoring**: Combines semantic similarity + keyword matching
- **Domain filtering**: Restrict answers to specific documentation sources

> **üí° Fresh Setup**: The bot starts with an empty knowledge base. You'll need to index your documentation (local files or web crawling) before asking questions. This ensures the bot only knows what you explicitly provide.

---

## Features Overview

### üìö **Document Processing**
- **Local files**: Markdown/TXT files in `./docs`
- **Web crawling**: Intelligent crawling with caching and robots.txt respect
- **Smart chunking**: Overlapping text chunks for better retrieval
- **Vector search**: Semantic similarity using local embeddings

### üîç **Question Answering**
- **RAG pipeline**: Retrieval-augmented generation with strict grounding
- **Confidence gating**: Configurable threshold for answer quality
- **Batch processing**: Handle multiple questions efficiently  
- **Performance metrics**: Response times and accuracy tracking

### üåê **Web Integration** 
- **HTTP caching**: ETag/Last-Modified support with content hashing
- **Domain whitelisting**: Security through allowed host lists
- **Force refresh**: Bypass caching when needed
- **Depth crawling**: Follow links with configurable depth limits

### üõ°Ô∏è **Reliability & Security**
- **No external APIs**: Everything runs locally with Ollama
- **Structured refusals**: Clear, consistent "don't know" responses  
- **Citation verification**: Track answer sources for validation
- **Error handling**: Graceful degradation and informative errors

---

## Installation & Setup

### Prerequisites
- **Python 3.11+**
- **Ollama**: [Install from ollama.com](https://ollama.com/)
- **4GB+ RAM**: For running local LLM models

### Step-by-Step Installation

1. **Install Ollama and models**
   ```bash
   # Install Ollama
   curl -fsSL https://ollama.com/install.sh | sh
   
   # Pull required models (this may take a few minutes)
   ollama pull llama3.1        # ~4GB - for text generation
   ollama pull nomic-embed-text # ~274MB - for embeddings
   
   # Verify installation
   ollama list
   ```

2. **Setup Python environment**
   ```bash
   git clone <your-repo-url>
   cd support-deflect-bot
   
   # Create virtual environment
   python -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   
   # Install dependencies  
   pip install -r requirements.txt
   ```

3. **Configure environment (optional)**
   ```bash
   cp .env.example .env
   # Edit .env to customize settings (see Configuration section)
   ```

4. **Add your documentation**
   ```bash
   # Add your .md and .txt files to the docs/ folder
   cp your-docs/*.md docs/
   ```

5. **Start the application**
   ```bash
   uvicorn src.api.app:app --reload --port 8000
   ```

6. **Index your documentation**
   ```bash
   # Index local files from ./docs folder  
   curl -X POST http://127.0.0.1:8000/reindex
   
   # Should return: {"chunks_indexed": N}
   ```

7. **Verify setup**
   ```bash
   # Check API health
   curl http://127.0.0.1:8000/healthz
   
   # Check LLM connectivity  
   curl http://127.0.0.1:8000/llm_ping
   
   # Test asking a question
   curl -X POST http://127.0.0.1:8000/ask \
     -H "Content-Type: application/json" \
     -d '{"question": "How do I configure the system?"}'
   ```

---

## API Usage Guide

### Core Endpoints

#### Health Check
```bash
curl http://127.0.0.1:8000/healthz
```

#### Index Documents
```bash
# Index local files from ./docs folder
curl -X POST http://127.0.0.1:8000/reindex

# Response: {"chunks_indexed": 42}
```

#### Ask Questions  
```bash
curl -X POST http://127.0.0.1:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "How do I enable debug mode?"}'

# Response:
{
  "answer": "Set DEBUG=true in your environment variables...",
  "citations": [
    {
      "rank": 1,
      "path": "configuration.md", 
      "chunk_id": 2,
      "preview": "Debug mode can be enabled by setting..."
    }
  ],
  "confidence": 0.85
}
```

#### Search Documents
```bash
curl -X POST http://127.0.0.1:8000/search \
  -H "Content-Type: application/json" \
  -d '{"query": "authentication", "k": 5}'
```

### Web Crawling

#### Crawl Specific URLs
```bash
curl -X POST http://127.0.0.1:8000/crawl \
  -H "Content-Type: application/json" \
  -d '{
    "urls": ["https://docs.python.org/3/library/venv.html"],
    "force": false
  }'
```

#### Crawl with Depth
```bash
curl -X POST http://127.0.0.1:8000/crawl_depth \
  -H "Content-Type: application/json" \
  -d '{
    "seeds": ["https://docs.python.org/3/"],
    "depth": 2,
    "max_pages": 50,
    "same_domain": true
  }'
```

#### Crawl Default Sites
```bash
curl -X POST http://127.0.0.1:8000/crawl_default
```

### Advanced Features

#### Domain Filtering
```bash
curl -X POST http://127.0.0.1:8000/ask \
  -H "Content-Type: application/json" \
  -d '{
    "question": "How to create virtual environments?",
    "domains": ["docs.python.org"]
  }'
```

#### Batch Processing
```bash
curl -X POST http://127.0.0.1:8000/batch_ask \
  -H "Content-Type: application/json" \
  -d '{
    "questions": [
      "How do I install packages?",
      "Where are logs stored?",
      "How to enable debugging?"
    ]
  }'
```

#### Performance Metrics
```bash
curl http://127.0.0.1:8000/metrics

# Response:
{
  "ask": {"count": 15, "p50_ms": 245.3, "p95_ms": 892.1},
  "search": {"count": 8, "p50_ms": 89.2, "p95_ms": 156.7},
  "version": "0.1.0"
}
```

---

## Configuration Guide

### Environment Variables

Create `.env` file or set environment variables:

```bash
# Application Settings
APP_NAME=Support Deflection Bot
APP_VERSION=0.1.0

# Ollama Configuration
OLLAMA_MODEL=llama3.1                    # LLM model for chat
OLLAMA_EMBED_MODEL=nomic-embed-text      # Embedding model
OLLAMA_HOST=http://localhost:11434       # Ollama service URL

# RAG Behavior
ANSWER_MIN_CONF=0.20                     # Confidence threshold (0.0-1.0)
MAX_CHUNKS=5                             # Max context chunks per query
MAX_CHARS_PER_CHUNK=800                  # Max characters per chunk

# Web Crawling
ALLOW_HOSTS=docs.python.org,pip.pypa.io  # Comma-separated allowed domains
TRUSTED_DOMAINS=help.sigmacomputing.com  # Domains that bypass robots.txt checks
CRAWL_DEPTH=1                            # Default crawl depth
CRAWL_MAX_PAGES=40                       # Max pages per crawl session
CRAWL_SAME_DOMAIN=true                   # Restrict to same domain

# Storage Paths
CHROMA_DB_PATH=./chroma_db               # Vector database location
DOCS_FOLDER=./docs                       # Local documentation folder
CRAWL_CACHE_PATH=./data/crawl_cache.json # Web crawl cache file
```

### Customization Examples

#### 1. Adjust Confidence Threshold
```bash
# Stricter (fewer answers, higher quality)
ANSWER_MIN_CONF=0.35

# More lenient (more answers, potentially lower quality)
ANSWER_MIN_CONF=0.15
```

#### 2. Configure for Different Domains
```bash
# Python documentation only
ALLOW_HOSTS=docs.python.org,packaging.python.org,pip.pypa.io

# JavaScript ecosystem
ALLOW_HOSTS=nodejs.org,npmjs.com,developer.mozilla.org

# Your company docs
ALLOW_HOSTS=docs.yourcompany.com,wiki.yourcompany.com
```

#### 3. Optimize for Different Use Cases
```bash
# Quick responses (less context)
MAX_CHUNKS=3
MAX_CHARS_PER_CHUNK=400

# Comprehensive answers (more context)
MAX_CHUNKS=8
MAX_CHARS_PER_CHUNK=1200
```

#### 4. Docker Configuration
```bash
# For Docker deployment with external Ollama
OLLAMA_HOST=http://host.docker.internal:11434  # macOS/Windows
OLLAMA_HOST=http://172.17.0.1:11434           # Linux
```

---

## Customization Recipes

### Recipe 1: Customer Support Bot

Perfect for customer support with company documentation.

**Configuration:**
```bash
ANSWER_MIN_CONF=0.30                     # High confidence for customer-facing
MAX_CHUNKS=5
ALLOW_HOSTS=docs.yourcompany.com,help.yourcompany.com
```

**Usage Pattern:**
```bash
# Index company docs
curl -X POST http://127.0.0.1:8000/crawl \
  -d '{"urls": ["https://docs.yourcompany.com/sitemap.xml"]}'

# Ask support questions with domain filtering
curl -X POST http://127.0.0.1:8000/ask \
  -d '{"question": "How do I reset my password?", "domains": ["docs.yourcompany.com"]}'
```

### Recipe 2: Development Documentation Assistant

For developers working with multiple technology stacks.

**Configuration:**
```bash
ANSWER_MIN_CONF=0.20                     # Balanced for technical questions
MAX_CHUNKS=7                             # More context for complex topics
ALLOW_HOSTS=docs.python.org,nodejs.org,docs.docker.com,kubernetes.io
```

**Usage Pattern:**
```bash
# Crawl multiple tech stacks
curl -X POST http://127.0.0.1:8000/crawl_depth \
  -d '{
    "seeds": [
      "https://docs.python.org/3/",
      "https://nodejs.org/en/docs/",
      "https://docs.docker.com/"
    ],
    "depth": 2,
    "max_pages": 100
  }'

# Ask with specific domain focus
curl -X POST http://127.0.0.1:8000/ask \
  -d '{"question": "How to set up Docker containers?", "domains": ["docs.docker.com"]}'
```

### Recipe 3: Academic Research Assistant

For processing academic papers and research documentation.

**Configuration:**
```bash
ANSWER_MIN_CONF=0.35                     # Very strict for academic accuracy
MAX_CHUNKS=10                            # Comprehensive context
MAX_CHARS_PER_CHUNK=1000                 # Longer chunks for detailed content
```

**Usage Pattern:**
```bash
# Index local research papers
mkdir docs/papers
cp *.pdf docs/papers/                    # Requires PDF processing setup

curl -X POST http://127.0.0.1:8000/reindex

# Batch queries for research
curl -X POST http://127.0.0.1:8000/batch_ask \
  -d '{
    "questions": [
      "What are the main findings in machine learning research?",
      "How do the authors define neural networks?",
      "What datasets were used in the experiments?"
    ]
  }'
```

### Recipe 4: Multi-language Documentation

For international documentation in multiple languages.

**Configuration:**
```bash
# Configure for multiple language domains
ALLOW_HOSTS=docs.python.org,docs.python.org/fr,docs.python.org/es,docs.python.org/de
```

**Custom crawling script:**
```bash
#!/bin/bash
# Crawl documentation in multiple languages
for lang in en fr es de; do
  curl -X POST http://127.0.0.1:8000/crawl \
    -d "{\"urls\": [\"https://docs.python.org/$lang/3/\"], \"force\": true}"
done
```

### Recipe 5: API Documentation Assistant

Specialized for API reference documentation.

**Configuration:**
```bash
ANSWER_MIN_CONF=0.25                     # Moderate confidence for API details
MAX_CHUNKS=6                             # Good context for examples
ALLOW_HOSTS=api.yourservice.com,swagger.io,postman.com
```

**Enhanced with custom metadata:**
```python
# Custom preprocessing for API docs
import requests

def crawl_api_docs():
    # Crawl API documentation
    response = requests.post("http://127.0.0.1:8000/crawl", json={
        "urls": [
            "https://api.yourservice.com/docs",
            "https://api.yourservice.com/reference",
            "https://api.yourservice.com/examples"
        ]
    })
    return response.json()

# Query with API-specific context
def ask_api_question(question):
    return requests.post("http://127.0.0.1:8000/ask", json={
        "question": f"API: {question}",
        "domains": ["api.yourservice.com"]
    }).json()
```

---

## Testing & Development

### Running Tests

```bash
# Install test dependencies
pip install pytest pytest-asyncio pytest-cov httpx

# Run all tests
pytest

# Run specific test categories
pytest tests/unit/ -v                    # Unit tests
pytest tests/integration/ -v             # API tests  
pytest tests/system/ -v -m requires_ollama # E2E tests (needs Ollama)

# Generate coverage report
pytest --cov=src --cov-report=html
```

### Development Workflow

```bash
# Code formatting and linting
pip install black flake8 isort
black src/ tests/
isort src/ tests/  
flake8 src/ tests/

# Run development server
uvicorn src.api.app:app --reload --log-level debug

# Monitor logs
tail -f ~/.ollama/logs/server.log        # Ollama logs
```

### Evaluation Framework

```bash
# Create evaluation dataset
echo '{"question": "How to install?", "type": "answer", "must_include": ["pip install"]}' > data/eval/test.jsonl

# Run evaluation
python -m src.utils.run_eval

# View results
cat data/eval/results_*.csv
```

---

## Deployment

### Docker Deployment

```bash
# Build image
docker build -t support-deflect-bot .

# Run with external Ollama (recommended)
docker run -d \
  -p 8000:8000 \
  -e OLLAMA_HOST=http://host.docker.internal:11434 \
  -v $(pwd)/docs:/app/docs \
  -v $(pwd)/chroma_db:/app/chroma_db \
  --name support-bot \
  support-deflect-bot

# Index your documents
curl -X POST http://127.0.0.1:8000/reindex
```

### Production Configuration

```bash
# Production environment variables
APP_VERSION=1.0.0
ANSWER_MIN_CONF=0.30                     # Stricter for production
CHROMA_DB_PATH=/data/chroma_db           # Persistent storage
CRAWL_CACHE_PATH=/data/crawl_cache.json
```

### Health Checks

```bash
# Basic health check
curl -f http://localhost:8000/healthz || exit 1

# LLM connectivity check  
curl -f http://localhost:8000/llm_ping || exit 1

# Full functionality test
curl -X POST http://localhost:8000/ask \
  -d '{"question": "test"}' \
  -H "Content-Type: application/json" | grep -q "answer"
```

---

## Performance Tuning

### Ollama Optimization

```bash
# Allocate more memory to Ollama
export OLLAMA_NUM_PARALLEL=2
export OLLAMA_MAX_LOADED_MODELS=2

# Use GPU if available
export OLLAMA_GPU=nvidia  # or amd, intel
```

### Database Optimization

```bash
# Optimize ChromaDB settings
export CHROMA_SERVER_HTTP_PORT=8001
export CHROMA_SERVER_CORS_ALLOW_ORIGINS="http://localhost:8000"
```

### Application Tuning

```python
# Adjust batch sizes in .env
MAX_CHUNKS=3                    # Faster responses
MAX_CHARS_PER_CHUNK=600        # Balanced context

# For high-throughput scenarios  
MAX_CHUNKS=8                   # More comprehensive answers
MAX_CHARS_PER_CHUNK=1000       # Richer context
```

---

## Troubleshooting

### Common Issues

**Ollama Connection Errors**
```bash
# Check if Ollama is running
curl http://localhost:11434/api/tags

# Restart Ollama service
systemctl restart ollama  # Linux
brew services restart ollama  # macOS

# Check model availability
ollama list
```

**Low Confidence Scores**
```bash
# Lower the confidence threshold
export ANSWER_MIN_CONF=0.15

# Add more relevant documents
cp additional-docs/*.md docs/
curl -X POST http://127.0.0.1:8000/reindex

# Check document quality
curl -X POST http://127.0.0.1:8000/search \
  -d '{"query": "your search terms", "k": 10}'
```

**Web Crawling Issues**
```bash
# Check domain restrictions
echo $ALLOW_HOSTS

# Force re-crawl
curl -X POST http://127.0.0.1:8000/crawl \
  -d '{"urls": ["https://example.com"], "force": true}'

# Check crawl cache
cat ./data/crawl_cache.json | jq
```

**Database Issues**
```bash
# Reset vector database
rm -rf ./chroma_db
curl -X POST http://127.0.0.1:8000/reindex

# Check database size
du -sh ./chroma_db

# Verify database contents  
python -c "
from src.data.store import get_collection
print(f'Documents: {get_collection().count()}')
"
```

### Performance Issues

```bash
# Monitor response times
curl -s -w '%{time_total}s\n' http://127.0.0.1:8000/ask \
  -d '{"question": "test"}' > /dev/null

# Check memory usage
htop | grep python

# Monitor Ollama performance
docker logs ollama -f  # if using Docker
```

### Debug Mode

```bash
# Enable debug logging
export LOG_LEVEL=debug
uvicorn src.api.app:app --log-level debug

# Inspect vector search results
curl -X POST http://127.0.0.1:8000/search \
  -d '{"query": "debug query", "k": 5}' | jq .
```

---

## Contributing

### Development Setup

```bash
# Clone and setup
git clone <repo>
cd support-deflect-bot
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
pip install -r requirements-dev.txt

# Run tests before committing
pytest
black src/ tests/
flake8 src/ tests/
```

### Code Quality

- **Type hints**: Use type annotations for all functions
- **Documentation**: Document all public functions and classes  
- **Testing**: Maintain >80% test coverage
- **Error handling**: Graceful failure with informative messages

---

## License

MIT License - see LICENSE file for details.

---

## Support & Community

- **Issues**: [GitHub Issues](link-to-issues)
- **Discussions**: [GitHub Discussions](link-to-discussions)  
- **Documentation**: [Full Documentation](link-to-docs)

Built with ‚ù§Ô∏è for reliable, grounded AI assistance.

