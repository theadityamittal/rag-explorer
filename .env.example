# Primary provider choices (pick available providers)
# Options for LLM: gemini | openai | anthropic | mistral | groq | ollama
# Options for Embeddings: gemini | openai | ollama
PRIMARY_LLM_PROVIDER="gemini"
PRIMARY_EMBEDDING_PROVIDER="gemini"

# API keys (fill what you intend to use)
GOOGLE_API_KEY=""
OPENAI_API_KEY=""
ANTHROPIC_API_KEY=""
MISTRAL_API_KEY=""
GROQ_API_KEY=""

# Local Ollama (optional)
# OLLAMA_HOST="http://localhost:11434"
OLLAMA_MODEL="llama3.1"
OLLAMA_EMBED_MODEL="nomic-embed-text"

# RAG confidence and retrieval knobs
ANSWER_MIN_CONF=0.25
MAX_CHUNKS=5
MAX_CHARS_PER_CHUNK=800

DOCS_FOLDER="./docs"

# Crawling basics (advanced domain allowlists are managed internally)
# Customize if you plan to crawl remote docs
DEFAULT_SEEDS="https://docs.python.org/3/faq/index.html,https://docs.python.org/3/library/venv.html"
CRAWL_DEPTH=1
CRAWL_MAX_PAGES=40
CRAWL_SAME_DOMAIN=true

# Optional overrides (rarely needed)
# CRAWL_USER_AGENT="SupportDeflectBot/0.2 (+https://example.local; contact: you@example.com)"
# CRAWL_CACHE_PATH="./data/crawl_cache.json"
# DOCS_SOURCES="./docs,./more-docs"

# Notes
# - Advanced/internal settings (provider strategy, budgets, compliance, vector store
#   paths, allowlists) ship with safe defaults and/or live in
#   ~/.support-deflect-bot/config.json via the interactive configurator.
# - Explicit environment variables always override internal config.
